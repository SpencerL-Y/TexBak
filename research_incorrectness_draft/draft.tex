\documentclass[a4paper,12pt]{article}
\usepackage{geometry}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{color}
\usepackage{stmaryrd}
\usepackage{multirow}
\usepackage{lscape}
\title{Discussion on Octagon}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newcommand{\cona}{\mathcal{A}}
\newcommand{\conb}{\mathcal{B}}
\newcommand{\conc}{\mathcal{C}}
\newcommand{\cond}{\mathcal{D}}
\geometry{a4paper, scale = 0.85}
\begin{document}
\maketitle

\section{Draft}
\paragraph{Synthesizing an Octagon Predicate $p$}

\begin{definition}[Octagon]
Given a set of variables $X$ where all variables in the set belongs to a numerical set $\mathbb{I}$, which can be $\mathbb{Z}, \mathbb{R}$ or $\mathbb{Q}$. We call \emph{octagonal constraint} any constraint of the form $\pm x_i \pm x_j \ge c$ where $c\in\mathbb{I}$ and $x_i,x_j\in X$. An \emph{octagon} is the set of points that satisfies the conjunction of all octagonal constraints. 


\end{definition}
Assume the program we consider is affine linear. From the definition of incorrectness logic and the iteration rule, our target is to synthesize a predicate $p(\mathbf{x},n)$ for a loop program where the update of the loop body can be expressed as $\mathbf{x}' = M\mathbf{x}$, s.t. 
\[\models \forall \mathbf{x}.n. (p(\mathbf{x},n+1) \implies \exists \mathbf{y}.\mathbf{x} = M\mathbf{y} \wedge p(\mathbf{y}, n))\]
After the elimination of the existential quantifier we get:
\[\models \forall \mathbf{x}.n. (p(\mathbf{x}, n+1) \implies p(k_0(\mathbf{x} - \mathbf{c}) + k_1\mathbf{v}_i, n))\]



\begin{example}

We first consider the simplest example where $X = \{x, n\}$, i.e. $\mathbf{x}$ only contains one variable. We assume the update of the program is $x' = ax + b$. The octagon is equivalently given by the form:


\begin{align*}
x + y \ge& \cona_{x,y}\\
x - y \ge& \conb_{x,y}\\
-x + y \ge& \conc_{x,y}\\
-x - y \ge& \cond_{x,y}\\
\end{align*}
where $x,y\in X$.

For this example, then the constraint system $S_1$ of $p(\mathbf{x}, n+1)$ can be given as:

\begin{align*}
2x&& &\ge \cona_{x,x}\\
&&0 &\ge \conb_{x,x}\\
&&0 &\ge \conc_{x,x}\\
-2x&& & \ge \cond_{x,x}\\
x &+ n& +1&\ge \cona_{x,n}\\
x &- n& +1&\ge \conb_{x,n}\\
-x &+ n& +1&\ge \conc_{x,n}\\
-x &- n&+1 &\ge \cond_{x,n}\\
&+2n & +2&\ge \cona_{n,n}\\
&& 0&\ge \conb_{n,n}\\
&& 0&\ge \conc_{n,n}\\
&-2n& -2&\ge\cond_{n,n}\\
\end{align*}
Similarly, from the fact that $\mathbf{y} = [y] = [\frac{1}{a} x - \frac{b}{a}]$, we can also derive a system $S_2$ for $p(\mathbf{y}, n)$:

\begin{align*}
\frac{2}{a}x&& -\frac{2b}{a} &\ge \cona_{x,x}\\
&&0 &\ge \conb_{x,x}\\
&&0 &\ge \conc_{x,x}\\
-\frac{2}{a}x&& \frac{2b}{a} &\ge \cond_{x,x}\\
\frac{1}{a}x &+ n& -\frac{b}{a}&\ge \cona_{x,n}\\
\frac{1}{a}x &- n& -\frac{b}{a}&\ge \conb_{x,n}\\
-\frac{1}{a}x &+ n& +\frac{b}{a}&\ge \conc_{x,n}\\
-\frac{1}{a}x &- n& +\frac{b}{a}&\ge \cond_{x,n}\\
&+2n &&\ge \cona_{n,n}\\
&& 0&\ge \conb_{n,n}\\
&& 0&\ge \conc_{n,n}\\
&-2n&&\ge\cond_{n,n}\\
\end{align*}

Target of the synthesis is to synthesize the unknown parameter $\{\cona, \conb, \conc, \cond\}$ s.t. $\models \forall x.n. (S_1\implies S_2)$.

According to the method in previous SAS'04, e.g. if we consider the implication 
\[\forall \mathbf{x}. (S_1\implies \frac{2}{a}x-\frac{2b}{a} \ge \cona_{x,x})\]
By introducing the symbol $\lambda^{\cona_{x,x}}_{\conb_{x,x}}$, we mean the parameter introduced during the application of Farkas' Lemma from the equation with parameter $\conb_{x,x}$ to the equation in $S_2$ with parameter $\cona_{x,x}$. Then for this instance of implication we have $\exists \lambda_{\cona_{x,x}}^{\cona_{x,x}}\ldots\lambda_{\cond_{n,n}}^{\cona_{x,x}}$. 
\begin{tiny}

\begin{landscape}
\begin{align*}
&+2\lambda_{\cona_{x,x}}^{\cona_{x,x}}&&& - 2\lambda_{\cond_{x,x}}^{\cona_{x,x}} &+ \lambda_{\cona_{x,n}}^{\cona_{x,x}} &+ \lambda_{\conb_{x,n}}^{\cona_{x,x}} &- \lambda_{\conc_{x,n}}^{\cona_{x,x}}&-\lambda_{\cond_{x,n}}^{\cona_{x,x}}&&&& &= \frac{2}{a}\\
&&&&&+\lambda_{\cona_{x,n}}^{\cona_{x,x}} &- \lambda_{\conb_{x,b}}^{\conb_{x,x}} &+ \lambda_{\conc_{x,n}}^{\cona_{x,x}} &- \lambda_{\cond_{x,n}}^{\cona_{x,x}} &+ 2\lambda_{\cona_{n,n}}^{\cona_{x,x}} &&&- 2\lambda_{\cond_{n,n}}^{\cona_{x,x}} &= 0\\
&-\lambda_{\cona_{x,x}}^{\cona_{x,x}}\cona_{x,x}&-\lambda_{\conb_{x,x}}^{\cona_{x,x}}\conb_{x,x}&-\lambda_{\conc_{x,x}}^{\cona_{x,x}}\conc_{x,x}&-\lambda_{\cond_{x,x}}^{\cona_{x,x}}\cond_{x,x}&+(1-\cona_{x,n})\lambda_{\cona_{x,n}}^{\cona_{x,x}}&+(1-\conb_{x,n})\lambda_{\conb_{x,n}}^{\cona_{x,x}}&+(1-\conc_{x,n})\lambda_{\conc_{x,n}}^{\cona_{x,x}}&+(1-\cond_{x,n})\lambda_{\cond_{x,n}}^{\cona_{x,x}}&+(2-\cona_{n,n})\lambda_{\cona_{n,n}}^{\cona_{x,x}}&-\conb_{n,n}\lambda_{\conb_{n,n}}^{\cona_{x,x}}&-\conc_{n,n}\lambda_{\conc_{n,n}}^{\cona_{x,x}}&+(2-\cond_{n,n})\lambda_{\cond_{n,n}}^{\cona_{x,x}} &= -\frac{2b}{a} - \cona_{x,x}\\
&-\lambda_{\cona_{x,x}}^{\cona_{x,x}}\cona_{x,x}&&&-\lambda_{\cond_{x,x}}^{\cona_{x,x}}\cond_{x,x}&+(1-\cona_{x,n})\lambda_{\cona_{x,n}}^{\cona_{x,x}}&+(1-\conb_{x,n})\lambda_{\conb_{x,n}}^{\cona_{x,x}}&+(1-\conc_{x,n})\lambda_{\conc_{x,n}}^{\cona_{x,x}}&+(1-\cond_{x,n})\lambda_{\cond_{x,n}}^{\cona_{x,x}}&+(2-\cona_{n,n})\lambda_{\cona_{n,n}}^{\cona_{x,x}}&&&+(2-\cond_{n,n})\lambda_{\cond_{n,n}}^{\cona_{x,x}} &= -\frac{2b}{a} - \cona_{x,x}\\
\end{align*}
\end{landscape}

\end{tiny}
The first three equations in page 3 are directly derived from the method.

Due to the fact that types of $\conb_{x,x}$ and $\conc_{x,x}$ can be directly assigned to $0$ and not influencing the result.

Without any assumption on the parameters, it seems the number of equations are not enough to remove all the nonlinear nomials in the equation of constant column.

However, observe the equation in the second line, we can add some assumptions according to the sum is $0$:
\begin{align*}
&&&&&+\lambda_{\cona_{x,n}}^{\cona_{x,x}} &- \lambda_{\conb_{x,b}}^{\conb_{x,x}} &+ \lambda_{\conc_{x,n}}^{\cona_{x,x}} &- \lambda_{\cond_{x,n}}^{\cona_{x,x}} &+ 2\lambda_{\cona_{n,n}}^{\cona_{x,x}} &&&- 2\lambda_{\cond_{n,n}}^{\cona_{x,x}} &= 0\\
\end{align*}


i.e. $\lambda_{\cona_{x,n}}^{\cona_{x,x}} = \lambda_{\conb_{x,b}}^{\conb_{x,x}}$,  $\lambda_{\conc_{x,n}}^{\cona_{x,x}} = \lambda_{\cond_{x,n}}^{\cona_{x,x}}$ and $\lambda_{\cona_{n,n}}^{\cona_{x,x}} = \lambda_{\cond_{n,n}}^{\cona_{x,x}}$.

These assumptions can help to remove the nonlinear nomials. 

But this situation only occurs when there is only one nomial with variable in the implied equation. If another equation is taking into consider, e.g. $\frac{1}{a}x+n -\frac{b}{a}\ge \cona_{x,n}$. The first two equation is similar to that of in page three except the RHS of the second equation in page 3 is not $0$. Observing that we can make use of equation $1$ and equation $2$ to produce equation whose RHS is $0$, thus resulting in a familiar analysis like before.

Hence, we can remove the nonlinear constraint by simply applying some assumptions obtained from the equations which is only related to $\lambda$s'.

This is just a trivial case where two variables $\{x,n\}$ are considered. Can we prove that this tactic can be applies to a system with $k\in\mathbb{N}$ variables? Seemingly yes, maybe by induction on the number of variables (A detailed proof needed.). Stopped here, deal with it later.




\end{example}


\end{document}